{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Custom\n",
    "import models.resnet as resnet\n",
    "import models.lossnet as lossnet\n",
    "from config import *\n",
    "from data.fst_data import train_data, test_data\n",
    "\n",
    "import timm\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "import datetime\n",
    "# Python\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "# Torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Torchvison\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "쿠다 가능 :False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "print(\"쿠다 가능 :{}\".format(torch.cuda.is_available()))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LossPredLoss(input, target, margin=1.0, reduction='mean'):\n",
    "    assert len(input) % 2 == 0, 'the batch size is not even.'\n",
    "    assert input.shape == input.flip(0).shape\n",
    "    \n",
    "    input = (input - input.flip(0))[:len(input)//2] # [l_1 - l_2B, l_2 - l_2B-1, ... , l_B - l_B+1], where batch_size = 2B\n",
    "    target = (target - target.flip(0))[:len(target)//2]\n",
    "    target = target.detach()\n",
    "\n",
    "    one = 2 * torch.sign(torch.clamp(target, min=0)) - 1 # 1 operation which is defined by the authors\n",
    "    \n",
    "    if reduction == 'mean':\n",
    "        loss = torch.sum(torch.clamp(margin - one * input, min=0))\n",
    "        loss = loss / input.size(0) # Note that the size of input is already halved\n",
    "    elif reduction == 'none':\n",
    "        loss = torch.clamp(margin - one * input, min=0)\n",
    "    else:\n",
    "        NotImplementedError()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Train Utils\n",
    "iters = 0\n",
    "\n",
    "\n",
    "def get_uncertainty(models, extractor, unlabeled_loader):\n",
    "    models['backbone'].eval()\n",
    "    models['module'].eval()\n",
    "    uncertainty = torch.tensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in unlabeled_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            scores = models['backbone'](inputs)\n",
    "            \n",
    "            features = extractor\n",
    "            pred_loss = models['module'](features) # pred_loss = criterion(scores, labels) # ground truth loss\n",
    "            pred_loss = pred_loss.view(pred_loss.size(0))\n",
    "\n",
    "            uncertainty = torch.cat((uncertainty, pred_loss), 0)\n",
    "    \n",
    "    return uncertainty.cpu()\n",
    "\n",
    "\n",
    "def test(models, extractor, dataloaders, mode='val'):\n",
    "    metrics = {}\n",
    "    preds, labels = [], []\n",
    "    assert mode == 'val' or mode == 'test'\n",
    "    models['backbone'].eval()\n",
    "    models['module'].eval()\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders[mode]:\n",
    "            inputs = data[0].to(device)\n",
    "            label = data[1].to(device)\n",
    "            # inputs = inputs.to(device)\n",
    "            # label = label.to(device)\n",
    "\n",
    "            scores = models['backbone'](inputs)\n",
    "            # _, preds = torch.max(scores.data, 1)\n",
    "            labels.extend(label.detach().tolist())\n",
    "            preds.extend(scores.argmax(axis=1).detach().tolist())\n",
    "        print(f\" labels = {labels}\")\n",
    "        print(f\" preds = {preds}\")\n",
    "        \n",
    "    metrics['accuracy'] = accuracy_score(y_pred=preds, y_true=labels)\n",
    "    metrics['f1_score'] = f1_score(y_pred=preds, y_true=labels, average='weighted')\n",
    "    metrics['precision'] = precision_score(y_pred=preds, y_true=labels, average='weighted')\n",
    "    metrics['recall'] = recall_score(y_pred=preds, y_true=labels, average='weighted')\n",
    "\n",
    "            # print(\"labels \" , labels)\n",
    "            # print(\"preds \" , preds)\n",
    "    return metrics\n",
    "\n",
    "#\n",
    "def train(models, extractor, criterion, optimizers, schedulers, dataloaders, num_epochs, epoch_loss):\n",
    "    print('>> Train a Model.')\n",
    "    best_acc = 0.\n",
    "    checkpoint_dir = os.path.join('./cifar10', 'train', 'weights')\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "            \n",
    "        train_epoch(models, extractor, criterion, optimizers, dataloaders, epoch, epoch_loss)\n",
    "        schedulers['backbone'].step()\n",
    "        schedulers['module'].step()\n",
    "\n",
    "    print('>> Finished.')\n",
    "    \n",
    "def train_epoch(models, extractor, criterion, optimizers, dataloaders, epoch, epoch_loss):\n",
    "    models['backbone'].train()\n",
    "    models['module'].train()\n",
    "    global iters\n",
    "\n",
    "    for data in tqdm(dataloaders['train'], leave=False, total=len(dataloaders['train'])):\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        img_name = data[2]\n",
    "        \n",
    "        iters += 1\n",
    "\n",
    "        optimizers['backbone'].zero_grad()\n",
    "        optimizers['module'].zero_grad()\n",
    "\n",
    "        scores = models['backbone'](inputs)\n",
    "        target_loss = criterion(scores, labels)\n",
    "        \n",
    "        features_dic = extractor(inputs)\n",
    "        features = [features_dic['layer1'], features_dic['layer2'], features_dic['layer3'], features_dic['layer4']]\n",
    "        \n",
    "        # print(f\" feature_length = {len(features)}\")\n",
    "        \n",
    "        # print(features)\n",
    "        \n",
    "        if epoch > epoch_loss:\n",
    "            # After 120 epochs, stop the gradient from the loss prediction module propagated to the target model.\n",
    "            features[0] = features[0].detach()\n",
    "            features[1] = features[1].detach()\n",
    "            features[2] = features[2].detach()\n",
    "            features[3] = features[3].detach()\n",
    "        \n",
    "            \n",
    "        pred_loss = models['module'](features)\n",
    "        pred_loss = pred_loss.view(pred_loss.size(0))\n",
    "\n",
    "\n",
    "        m_backbone_loss = torch.sum(target_loss) / target_loss.size(0)\n",
    "        m_module_loss   = LossPredLoss(pred_loss, target_loss, margin=MARGIN)\n",
    "        loss            = m_backbone_loss + WEIGHT * m_module_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizers['backbone'].step()\n",
    "        optimizers['module'].step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.relu_1', 'layer1.0.conv3', 'layer1.0.bn3', 'layer1.0.downsample.0', 'layer1.0.downsample.1', 'layer1.0.add', 'layer1.0.relu_2', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.relu_1', 'layer1.1.conv3', 'layer1.1.bn3', 'layer1.1.add', 'layer1.1.relu_2', 'layer1.2.conv1', 'layer1.2.bn1', 'layer1.2.relu', 'layer1.2.conv2', 'layer1.2.bn2', 'layer1.2.relu_1', 'layer1.2.conv3', 'layer1.2.bn3', 'layer1.2.add', 'layer1.2.relu_2', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.relu_1', 'layer2.0.conv3', 'layer2.0.bn3', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_2', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.relu_1', 'layer2.1.conv3', 'layer2.1.bn3', 'layer2.1.add', 'layer2.1.relu_2', 'layer2.2.conv1', 'layer2.2.bn1', 'layer2.2.relu', 'layer2.2.conv2', 'layer2.2.bn2', 'layer2.2.relu_1', 'layer2.2.conv3', 'layer2.2.bn3', 'layer2.2.add', 'layer2.2.relu_2', 'layer2.3.conv1', 'layer2.3.bn1', 'layer2.3.relu', 'layer2.3.conv2', 'layer2.3.bn2', 'layer2.3.relu_1', 'layer2.3.conv3', 'layer2.3.bn3', 'layer2.3.add', 'layer2.3.relu_2', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.relu_1', 'layer3.0.conv3', 'layer3.0.bn3', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_2', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.relu_1', 'layer3.1.conv3', 'layer3.1.bn3', 'layer3.1.add', 'layer3.1.relu_2', 'layer3.2.conv1', 'layer3.2.bn1', 'layer3.2.relu', 'layer3.2.conv2', 'layer3.2.bn2', 'layer3.2.relu_1', 'layer3.2.conv3', 'layer3.2.bn3', 'layer3.2.add', 'layer3.2.relu_2', 'layer3.3.conv1', 'layer3.3.bn1', 'layer3.3.relu', 'layer3.3.conv2', 'layer3.3.bn2', 'layer3.3.relu_1', 'layer3.3.conv3', 'layer3.3.bn3', 'layer3.3.add', 'layer3.3.relu_2', 'layer3.4.conv1', 'layer3.4.bn1', 'layer3.4.relu', 'layer3.4.conv2', 'layer3.4.bn2', 'layer3.4.relu_1', 'layer3.4.conv3', 'layer3.4.bn3', 'layer3.4.add', 'layer3.4.relu_2', 'layer3.5.conv1', 'layer3.5.bn1', 'layer3.5.relu', 'layer3.5.conv2', 'layer3.5.bn2', 'layer3.5.relu_1', 'layer3.5.conv3', 'layer3.5.bn3', 'layer3.5.add', 'layer3.5.relu_2', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.relu_1', 'layer4.0.conv3', 'layer4.0.bn3', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_2', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.relu_1', 'layer4.1.conv3', 'layer4.1.bn3', 'layer4.1.add', 'layer4.1.relu_2', 'layer4.2.conv1', 'layer4.2.bn1', 'layer4.2.relu', 'layer4.2.conv2', 'layer4.2.bn2', 'layer4.2.relu_1', 'layer4.2.conv3', 'layer4.2.bn3', 'layer4.2.add', 'layer4.2.relu_2', 'avgpool', 'flatten', 'fc']\n",
      "\n",
      "['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.relu_1', 'layer1.0.conv3', 'layer1.0.bn3', 'layer1.0.downsample.0', 'layer1.0.downsample.1', 'layer1.0.add', 'layer1.0.relu_2', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.relu_1', 'layer1.1.conv3', 'layer1.1.bn3', 'layer1.1.add', 'layer1.1.relu_2', 'layer1.2.conv1', 'layer1.2.bn1', 'layer1.2.relu', 'layer1.2.conv2', 'layer1.2.bn2', 'layer1.2.relu_1', 'layer1.2.conv3', 'layer1.2.bn3', 'layer1.2.add', 'layer1.2.relu_2', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.relu_1', 'layer2.0.conv3', 'layer2.0.bn3', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_2', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.relu_1', 'layer2.1.conv3', 'layer2.1.bn3', 'layer2.1.add', 'layer2.1.relu_2', 'layer2.2.conv1', 'layer2.2.bn1', 'layer2.2.relu', 'layer2.2.conv2', 'layer2.2.bn2', 'layer2.2.relu_1', 'layer2.2.conv3', 'layer2.2.bn3', 'layer2.2.add', 'layer2.2.relu_2', 'layer2.3.conv1', 'layer2.3.bn1', 'layer2.3.relu', 'layer2.3.conv2', 'layer2.3.bn2', 'layer2.3.relu_1', 'layer2.3.conv3', 'layer2.3.bn3', 'layer2.3.add', 'layer2.3.relu_2', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.relu_1', 'layer3.0.conv3', 'layer3.0.bn3', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_2', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.relu_1', 'layer3.1.conv3', 'layer3.1.bn3', 'layer3.1.add', 'layer3.1.relu_2', 'layer3.2.conv1', 'layer3.2.bn1', 'layer3.2.relu', 'layer3.2.conv2', 'layer3.2.bn2', 'layer3.2.relu_1', 'layer3.2.conv3', 'layer3.2.bn3', 'layer3.2.add', 'layer3.2.relu_2', 'layer3.3.conv1', 'layer3.3.bn1', 'layer3.3.relu', 'layer3.3.conv2', 'layer3.3.bn2', 'layer3.3.relu_1', 'layer3.3.conv3', 'layer3.3.bn3', 'layer3.3.add', 'layer3.3.relu_2', 'layer3.4.conv1', 'layer3.4.bn1', 'layer3.4.relu', 'layer3.4.conv2', 'layer3.4.bn2', 'layer3.4.relu_1', 'layer3.4.conv3', 'layer3.4.bn3', 'layer3.4.add', 'layer3.4.relu_2', 'layer3.5.conv1', 'layer3.5.bn1', 'layer3.5.relu', 'layer3.5.conv2', 'layer3.5.bn2', 'layer3.5.relu_1', 'layer3.5.conv3', 'layer3.5.bn3', 'layer3.5.add', 'layer3.5.relu_2', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.relu_1', 'layer4.0.conv3', 'layer4.0.bn3', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_2', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.relu_1', 'layer4.1.conv3', 'layer4.1.bn3', 'layer4.1.add', 'layer4.1.relu_2', 'layer4.2.conv1', 'layer4.2.bn1', 'layer4.2.relu', 'layer4.2.conv2', 'layer4.2.bn2', 'layer4.2.relu_1', 'layer4.2.conv3', 'layer4.2.bn3', 'layer4.2.add', 'layer4.2.relu_2', 'avgpool', 'flatten', 'fc']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "node: 'layer5' is not present in model. Hint: use `get_graph_node_names` to make sure the `return_nodes` you specified are present. It may even be that you need to specify `train_return_nodes` and `eval_return_nodes` separately.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/km/s7fx7g3j0kv6t0v6mw7hbb0r0000gn/T/ipykernel_8220/169678017.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m extractor = create_feature_extractor(\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mres101\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     return_nodes=[\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/feature_extraction.py\u001b[0m in \u001b[0;36mcreate_feature_extractor\u001b[0;34m(model, return_nodes, train_return_nodes, eval_return_nodes, tracer_kwargs, suppress_diff_warning)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;31m# one of the available names starts with it up to a .\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"^{query}(\\.|$)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavailable_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    503\u001b[0m                     \u001b[0;34mf\"node: '{query}' is not present in model. Hint: use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                     \u001b[0;34m\"`get_graph_node_names` to make sure the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: node: 'layer5' is not present in model. Hint: use `get_graph_node_names` to make sure the `return_nodes` you specified are present. It may even be that you need to specify `train_return_nodes` and `eval_return_nodes` separately."
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH, \n",
    "                                  num_workers = 1, pin_memory=True,  drop_last = True)\n",
    "test_loader  = DataLoader(test_data,num_workers = 1, batch_size=1)\n",
    "\n",
    "dataloaders  = {'train': train_loader, 'test': test_loader}\n",
    "\n",
    "res101 = resnet50(weights=None).to(device)\n",
    "# train_nodes, eval_nodes = get_graph_node_names(res101)\n",
    "# print(train_nodes)\n",
    "# print()\n",
    "# print(eval_nodes)\n",
    "\n",
    "extractor = create_feature_extractor(\n",
    "    res101,\n",
    "    return_nodes=[\n",
    "        \"layer1\",\n",
    "        \"layer2\",\n",
    "        \"layer3\",\n",
    "        \"layer4\",\n",
    "        # \"layer5\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# features = extractor(img)   \n",
    "# print(len(features))\n",
    "\n",
    "# print(f\"resnet summary : {summary_(resnet18, (3, 32, 32))}\")\n",
    "\n",
    "# resnet18 = timm.create_model(\"resnet50\", num_classes = 4, pretrained=True).to(device)\n",
    "loss_module = lossnet.LossNet().to(device)\n",
    "models      = {'backbone': res101 , 'module': loss_module}\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Active learning cycles\n",
    "for cycle in range(CYCLES):\n",
    "    # Loss, criterion and scheduler (re)initialization\n",
    "    criterion      = nn.CrossEntropyLoss(reduction='none')\n",
    "    optim_backbone = optim.SGD(models['backbone'].parameters(), lr=LR, \n",
    "                            momentum=MOMENTUM, weight_decay=WDECAY)\n",
    "    optim_module   = optim.SGD(models['module'].parameters(), lr=LR, \n",
    "                            momentum=MOMENTUM, weight_decay=WDECAY)\n",
    "    sched_backbone = lr_scheduler.MultiStepLR(optim_backbone, milestones=MILESTONES)\n",
    "    sched_module   = lr_scheduler.MultiStepLR(optim_module, milestones=MILESTONES)\n",
    "\n",
    "    optimizers = {'backbone': optim_backbone, 'module': optim_module}\n",
    "    schedulers = {'backbone': sched_backbone, 'module': sched_module}\n",
    "\n",
    "    # Training and test\n",
    "    train(models, extractor, criterion, optimizers, schedulers, dataloaders, EPOCH, EPOCHL)\n",
    "    metrics = test(models, extractor, dataloaders, mode='test')\n",
    "    \n",
    "    print(f\"accuracy : {metrics['accuracy']:.4f}\")\n",
    "    print(f\"f1 score : {metrics['f1_score']:.4f}\")\n",
    "    print(f\"precision : {metrics['precision']:.4f}\")\n",
    "    print(f\"recall : {metrics['recall']:.4f}\")\n",
    "    print('Trial {}/{} || Cycle {}/{} || Label set size {}'.format(trial+1, TRIALS, cycle+1, CYCLES, len(labeled_set)))\n",
    "    \n",
    "    \n",
    "    acc_list.append(metrics['accuracy'])\n",
    "    f1_list.append(metrics['f1_score'])\n",
    "    ##\n",
    "    #  Update the labeled dataset via loss prediction-based uncertainty measurement\n",
    "\n",
    "    # Randomly sample 10000 unlabeled data points\n",
    "    random.shuffle(unlabeled_set)\n",
    "    subset = unlabeled_set[:SUBSET]\n",
    "\n",
    "    # Create unlabeled dataloader for the unlabeled subset\n",
    "    unlabeled_loader = DataLoader(unlabeled_data, batch_size=BATCH, \n",
    "                                    sampler=SubsetSequentialSampler(subset), # more convenient if we maintain the order of subset\n",
    "                                    num_workers = 1, pin_memory=True,  drop_last = True)\n",
    "\n",
    "    # Measure uncertainty of each data points in the subset\n",
    "    uncertainty = get_uncertainty(models, extractor, unlabeled_loader)\n",
    "\n",
    "    # Index in ascending order\n",
    "    arg = np.argsort(uncertainty)\n",
    "    \n",
    "    # Update the labeled dataset and the unlabeled dataset, respectively\n",
    "    labeled_set += list(torch.tensor(subset)[arg][-ADDENDUM:].numpy())\n",
    "    unlabeled_set = list(torch.tensor(subset)[arg][:-ADDENDUM].numpy()) + unlabeled_set[SUBSET:]\n",
    "\n",
    "    # Create a new dataloader for the updated labeled dataset\n",
    "    \n",
    "    train_subset = SubsetRandomSampler(labeled_set)\n",
    "    \n",
    "    dataloaders['train'] = DataLoader(train_data, batch_size=BATCH, \n",
    "                                        sampler=train_subset, \n",
    "                                        num_workers = 1, pin_memory=True,  drop_last = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"accuracy : {metrics['accuracy']:.4f}\")\n",
    "print(f\"f1 score : {metrics['f1_score']:.4f}\")\n",
    "print(f\"precision : {metrics['precision']:.4f}\")\n",
    "print(f\"recall : {metrics['recall']:.4f}\")\n",
    "print('Trial {}/{} || Cycle {}/{} || Label set size {}'.format(trial+1, TRIALS, cycle+1, CYCLES, len(labeled_set)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Custom\n",
    "import models.resnet as resnet\n",
    "import models.lossnet as lossnet\n",
    "from config import *\n",
    "from data.fst_data import train_data, test_data\n",
    "\n",
    "import timm\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "import datetime\n",
    "# Python\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "# Torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Torchvison\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "model1 = timm.create_model('resnet50', num_classes = 4, pretrained=True, features_only = True, out_indices = (1,2,3,4))\n",
    "model2 = timm.create_model('resnet50', num_classes = 4, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "img = Image.open(\"/Users/ibyeong-gwon/Desktop/Git/DeepLearning/211201-AT6T31EH-M232_inpaint_1 ADR_W1.6_H1.7_FS.jpg\")\n",
    "train_transform = T.Compose([\n",
    "    # transforms.Resize((32, 32)),\n",
    "    # transforms.Resize((224, 224)),\n",
    "    transforms.Resize((360, 360)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    # T.RandomCrop(size=360, padding=4),\n",
    "    \n",
    "    T.ToTensor(),\n",
    "    \n",
    "    # T.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]) # T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) # CIFAR-100\n",
    "])\n",
    "\n",
    "img = train_transform(img)\n",
    "img = img.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "img = Image.open(\"/Users/ibyeong-gwon/Desktop/Git/DeepLearning/211201-AT6T31EH-M232_inpaint_1 ADR_W1.6_H1.7_FS.jpg\")\n",
    "img = train_transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "out4 = model1(img)[3]\n",
    "out = F.avg_pool2d(out4, 4)\n",
    "        # print(out.shape)\n",
    "out = out.view(out.size(0), -1)\n",
    "print(\"out shape = \",out.shape)\n",
    "\n",
    "linear = nn.Linear(18432, 4)\n",
    "\n",
    "out = linear(out)\n",
    "\n",
    "print(out)\n",
    "\n",
    "print(model2(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = timm.create_model('resnet50', num_classes = 4, pretrained=True)\n",
    "model2.forward_features(img).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model1(img)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "res101 = models.resnet50(pretrained=True)\n",
    "\n",
    "extractor = create_feature_extractor(\n",
    "    res101,\n",
    "    return_nodes=[\n",
    "        \"layer1\",\n",
    "        \"layer2\",\n",
    "        \"layer3\",\n",
    "        \"layer4\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "features = extractor(img)   \n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39523b5506b09c1341afcde84115bb5b8a9de94ca361b7e653f8ee467cc4d43c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
