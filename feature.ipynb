{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from my_dataset2 import MyDataset, collate_skip_empty, colors_per_class\n",
    "\n",
    "\n",
    "def fix_random_seeds():\n",
    "    seed = 50\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    " \n",
    "def get_features(dataset, batch, num_images):\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "\n",
    "    model = timm.create_model('resnet50', num_classes=4)\n",
    "    model = model.load_state_dict(torch.load('C:\\\\Users\\\\rtm\\Desktop\\\\tsne_new\\\\best.pt'))\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    dataset = MyDataset(dataset, num_images)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch, collate_fn=collate_skip_empty, shuffle=True)\n",
    "\n",
    "    # feature 저장 변수\n",
    "    features = None\n",
    "\n",
    "    # label 저장, image_path 저장\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc='Running the model inference'):\n",
    "        images = batch['image'].to(device)\n",
    "        labels += batch['label']\n",
    "        image_paths += batch['image_path']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.forward_features(images)\n",
    "\n",
    "        current_features = output.cpu().numpy()\n",
    "        if features is not None:\n",
    "            features = np.concatenate((features, current_features))\n",
    "        else:\n",
    "            features = current_features\n",
    "\n",
    "    return features, labels, image_paths\n",
    "\n",
    "\n",
    "# scale and move the coordinates so they fit [0; 1] range\n",
    "def scale_to_01_range(x):\n",
    "    # compute the distribution range\n",
    "    value_range = (np.max(x) - np.min(x))\n",
    "\n",
    "    # move the distribution so that it starts from zero\n",
    "    # by extracting the minimal value from all its values\n",
    "    starts_from_zero = x - np.min(x)\n",
    "\n",
    "    # make the distribution fit [0; 1] by dividing by its range\n",
    "    return starts_from_zero / value_range\n",
    "\n",
    "\n",
    "def scale_image(image, max_image_size):\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    scale = max(1, image_width / max_image_size, image_height / max_image_size)\n",
    "    image_width = int(image_width / scale)\n",
    "    image_height = int(image_height / scale)\n",
    "\n",
    "    image = cv2.resize(image, (image_width, image_height))\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_rectangle_by_class(image, label):\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # get the color corresponding to image class\n",
    "    color = colors_per_class[label]\n",
    "    image = cv2.rectangle(image, (0, 0), (image_width - 1, image_height - 1), color=color, thickness=5)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def compute_plot_coordinates(image, x, y, image_centers_area_size, offset):\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # compute the image center coordinates on the plot\n",
    "    center_x = int(image_centers_area_size * x) + offset\n",
    "\n",
    "    # in matplotlib, the y axis is directed upward\n",
    "    # to have the same here, we need to mirror the y coordinate\n",
    "    center_y = int(image_centers_area_size * (1 - y)) + offset\n",
    "\n",
    "    # knowing the image center, compute the coordinates of the top left and bottom right corner\n",
    "    tl_x = center_x - int(image_width / 2)\n",
    "    tl_y = center_y - int(image_height / 2)\n",
    "\n",
    "    br_x = tl_x + image_width\n",
    "    br_y = tl_y + image_height\n",
    "\n",
    "    return tl_x, tl_y, br_x, br_y\n",
    "\n",
    "\n",
    "# TSNE 에서 이미지로 나타내기\n",
    "def visualize_tsne_images(tx, ty, images, labels, plot_size=1000, max_image_size=100):\n",
    "   # 이미지 정중앙에 놓기\n",
    "    offset = max_image_size // 2\n",
    "    image_centers_area_size = plot_size - 2 * offset\n",
    "\n",
    "    tsne_plot = 255 * np.ones((plot_size, plot_size, 3), np.uint8)\n",
    "\n",
    "    for image_path, label, x, y in tqdm(\n",
    "            zip(images, labels, tx, ty),\n",
    "            desc='Building the T-SNE plot',\n",
    "            total=len(images)\n",
    "    ):\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        image = scale_image(image, max_image_size)\n",
    "        image = draw_rectangle_by_class(image, label)\n",
    "\n",
    "        tl_x, tl_y, br_x, br_y = compute_plot_coordinates(image, x, y, image_centers_area_size, offset)\n",
    "\n",
    "        tsne_plot[tl_y:br_y, tl_x:br_x, :] = image\n",
    "\n",
    "    plt.imshow(tsne_plot[:, :, ::-1])\n",
    "    plt.show()\n",
    "\n",
    "# TSNE 점으로 찍기\n",
    "def visualize_tsne_points(tx, ty, labels):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    for label in colors_per_class:\n",
    "        indices = [i for i, l in enumerate(labels) if l == label]\n",
    "\n",
    "        current_tx = np.take(tx, indices)\n",
    "        current_ty = np.take(ty, indices)\n",
    "\n",
    "        color = np.array([colors_per_class[label][::-1]], dtype=np.float) / 255\n",
    "\n",
    "        ax.scatter(current_tx, current_ty, c=color, label=label)\n",
    "\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "    plt.show()\n",
    "    #plt.savefig('local_tsne_5000')\n",
    "\n",
    "\n",
    "def visualize_tsne(tsne, images, labels, plot_size=1000, max_image_size=100):\n",
    "    tx = tsne[:, 0]\n",
    "    ty = tsne[:, 1]\n",
    "\n",
    "    tx = scale_to_01_range(tx)\n",
    "    ty = scale_to_01_range(ty)\n",
    "\n",
    "    visualize_tsne_points(tx, ty, labels)\n",
    "\n",
    "    #visualize_tsne_images(tx, ty, images, labels, plot_size=plot_size, max_image_size=max_image_size)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--path', type=str, default='data')\n",
    "    parser.add_argument('--batch', type=int, default=64)\n",
    "    parser.add_argument('--num_images', type=int, default=500)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    fix_random_seeds()\n",
    "\n",
    "    features, labels, image_paths = get_features(\n",
    "        dataset=args.path,\n",
    "        batch=args.batch,\n",
    "        num_images=args.num_images\n",
    "    )\n",
    "    print(features.shape)\n",
    "\n",
    "    tsne = TSNE(n_components=2,perplexity=20, n_iter=1000,).fit_transform(features)\n",
    "\n",
    "    visualize_tsne(tsne, image_paths, labels)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39523b5506b09c1341afcde84115bb5b8a9de94ca361b7e653f8ee467cc4d43c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
