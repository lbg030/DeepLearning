{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def testing(dataloaders):\n",
    "    labeling = {\n",
    "        '0': 0,\n",
    "        '1': 0,\n",
    "        '2': 0,\n",
    "        '3': 0,\n",
    "    }\n",
    "    print(f\"len dataloaders['train'] = {len(dataloaders['train'])}\")\n",
    "    for _ in range(len(dataloaders['train'])):\n",
    "        images, labels = next(iter(dataloaders['train']))\n",
    "        for i in range(4):\n",
    "            images.shape  # torch.Size([32, 1, 28, 28])\n",
    "\n",
    "            labels.shape # torch.Size([32])\n",
    "\n",
    "            import numpy as np\n",
    "            import matplotlib.pyplot as plt\n",
    "            %matplotlib inline\n",
    "\n",
    "            images[i].shape  #  torch.Size([1, 28, 28])\n",
    "\n",
    "            torch_image = torch.squeeze(images[0]) # 0 번째를 없애준다. \n",
    "            torch_image = torch.squeeze(torch_image[0]) \n",
    "            torch_image.shape   #  torch.Size([28, 28])\n",
    "\n",
    "            # 토치를 넘파이화 해줌 \n",
    "            image = torch_image.numpy()\n",
    "            image.shape\n",
    "\n",
    "            label = labels[i].numpy()   # array (9)\n",
    "            labeling[str(int(label))] += 1\n",
    "\n",
    "    print(labeling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE # sklearn 사용하면 easy !! \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def see(model, train_loader):\n",
    "    device = 'cuda:2'\n",
    "    actual = []\n",
    "    deep_features = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        images, labels = data.to(device), target.to(device)\n",
    "        features = model['backbone'](images) # 512 차원\n",
    "\n",
    "        deep_features += features.cpu().detach().numpy().tolist()\n",
    "        actual += labels.cpu().numpy().tolist()\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=0) # 사실 easy 함 sklearn 사용하니..\n",
    "    cluster = np.array(tsne.fit_transform(np.array(deep_features)))\n",
    "    actual = np.array(actual)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    cifar = ['hz','bz','chem','yd']\n",
    "    for i, label in zip(range(10), cifar):\n",
    "        idx = np.where(actual == i)\n",
    "        plt.scatter(cluster[idx, 0], cluster[idx, 1], marker='.', label=label)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: fst\n",
      "Method type:CoreSet\n",
      "data_train = 2675,  data_test = 670\n",
      "no_train = 2600\n",
      "len dataloaders['train'] = 20\n",
      "{'0': 49, '1': 13, '2': 12, '3': 6}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:02<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6448\n",
      "f1 score : 0.5085\n",
      "precision : 0.4198\n",
      "recall : 0.6448\n",
      "Trial 1/5 || Cycle 1/5 || Label set size 80\n",
      "Getting transformed features...\n",
      "Calculating distances...\n",
      "Using flat_X as features.\n",
      "Maximum distance from cluster centers is 0.01\n",
      "len dataloaders['train'] = 40\n",
      "{'0': 98, '1': 31, '2': 23, '3': 8}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:24<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6463\n",
      "f1 score : 0.5074\n",
      "precision : 0.4177\n",
      "recall : 0.6463\n",
      "Trial 1/5 || Cycle 2/5 || Label set size 160\n",
      "Getting transformed features...\n",
      "Calculating distances...\n",
      "Using flat_X as features.\n",
      "Maximum distance from cluster centers is 0.00\n",
      "len dataloaders['train'] = 60\n",
      "{'0': 100, '1': 34, '2': 95, '3': 11}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:55<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.1239\n",
      "f1 score : 0.0273\n",
      "precision : 0.0153\n",
      "recall : 0.1239\n",
      "Trial 1/5 || Cycle 3/5 || Label set size 240\n",
      "Getting transformed features...\n",
      "Calculating distances...\n",
      "Using flat_X as features.\n",
      "Maximum distance from cluster centers is 0.00\n",
      "len dataloaders['train'] = 80\n",
      "{'0': 182, '1': 32, '2': 96, '3': 10}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [07:18<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6463\n",
      "f1 score : 0.5074\n",
      "precision : 0.4177\n",
      "recall : 0.6463\n",
      "Trial 1/5 || Cycle 4/5 || Label set size 320\n",
      "Getting transformed features...\n",
      "Calculating distances...\n",
      "Using flat_X as features.\n",
      "Maximum distance from cluster centers is 0.00\n",
      "len dataloaders['train'] = 100\n",
      "{'0': 179, '1': 27, '2': 187, '3': 7}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [08:48<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.1239\n",
      "f1 score : 0.0273\n",
      "precision : 0.0153\n",
      "recall : 0.1239\n",
      "Trial 1/5 || Cycle 5/5 || Label set size 400\n",
      "Finished.\n",
      "data_train = 2675,  data_test = 670\n",
      "no_train = 2600\n",
      "len dataloaders['train'] = 20\n",
      "{'0': 60, '1': 13, '2': 3, '3': 4}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:59<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6463\n",
      "f1 score : 0.5104\n",
      "precision : 0.4395\n",
      "recall : 0.6463\n",
      "Trial 2/5 || Cycle 1/5 || Label set size 80\n",
      "Getting transformed features...\n",
      "Calculating distances...\n",
      "Using flat_X as features.\n",
      "Maximum distance from cluster centers is 0.02\n",
      "len dataloaders['train'] = 40\n",
      "{'0': 112, '1': 30, '2': 7, '3': 11}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:22<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6463\n",
      "f1 score : 0.5074\n",
      "precision : 0.4177\n",
      "recall : 0.6463\n",
      "Trial 2/5 || Cycle 2/5 || Label set size 160\n",
      "Getting transformed features...\n",
      "Calculating distances...\n",
      "Using flat_X as features.\n",
      "Maximum distance from cluster centers is 0.00\n",
      "len dataloaders['train'] = 60\n",
      "{'0': 185, '1': 25, '2': 16, '3': 14}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:49<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6463\n",
      "f1 score : 0.5074\n",
      "precision : 0.4177\n",
      "recall : 0.6463\n",
      "Trial 2/5 || Cycle 3/5 || Label set size 240\n",
      "Getting transformed features...\n",
      "Calculating distances...\n",
      "Using flat_X as features.\n",
      "Maximum distance from cluster centers is 0.00\n",
      "len dataloaders['train'] = 80\n",
      "{'0': 265, '1': 31, '2': 8, '3': 16}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [07:22<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6463\n",
      "f1 score : 0.5074\n",
      "precision : 0.4177\n",
      "recall : 0.6463\n",
      "Trial 2/5 || Cycle 4/5 || Label set size 320\n",
      "Getting transformed features...\n",
      "Calculating distances...\n",
      "Using flat_X as features.\n",
      "Maximum distance from cluster centers is 0.00\n",
      "len dataloaders['train'] = 100\n",
      "{'0': 351, '1': 24, '2': 16, '3': 9}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [08:49<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6463\n",
      "f1 score : 0.5074\n",
      "precision : 0.4177\n",
      "recall : 0.6463\n",
      "Trial 2/5 || Cycle 5/5 || Label set size 400\n",
      "Finished.\n",
      "data_train = 2675,  data_test = 670\n",
      "no_train = 2600\n",
      "len dataloaders['train'] = 20\n",
      "{'0': 57, '1': 8, '2': 12, '3': 3}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:59<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6060\n",
      "f1 score : 0.5031\n",
      "precision : 0.4301\n",
      "recall : 0.6060\n",
      "Trial 3/5 || Cycle 1/5 || Label set size 80\n",
      "Getting transformed features...\n",
      "Calculating distances...\n",
      "Using flat_X as features.\n",
      "Maximum distance from cluster centers is 0.01\n",
      "len dataloaders['train'] = 40\n",
      "{'0': 87, '1': 36, '2': 27, '3': 10}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:26<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6463\n",
      "f1 score : 0.5074\n",
      "precision : 0.4177\n",
      "recall : 0.6463\n",
      "Trial 3/5 || Cycle 2/5 || Label set size 160\n",
      "Getting transformed features...\n",
      "Calculating distances...\n",
      "Using flat_X as features.\n",
      "Maximum distance from cluster centers is 0.00\n",
      "len dataloaders['train'] = 60\n",
      "{'0': 180, '1': 27, '2': 20, '3': 13}\n",
      ">> Train a Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:38<05:30,  1.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1161770/601731886.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# Training and testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedulers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_of_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;31m# print(f'train loss : {train_loss:.4f}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# metrics['train_loss'] = round(train_loss, 4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/luna/workspaces/Intern/coreset/train_test.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(models, method, criterion, optimizers, schedulers, dataloaders, num_epochs, epoch_loss)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0munused_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mschedulers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backbone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/luna/workspaces/Intern/coreset/train_test.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(models, method, criterion, optimizers, dataloaders, epoch, epoch_loss)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backbone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backbone'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mtarget_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/luna/workspaces/Intern/coreset/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/luna/workspaces/Intern/coreset/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "GCN Active Learning\n",
    "'''\n",
    "\n",
    "# Python\n",
    "# import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "# import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import argparse \n",
    "# Custom\n",
    "import models.resnet as resnet\n",
    "from train_test import train, test\n",
    "from load_dataset import load_dataset\n",
    "from selection_methods import query_samples\n",
    "from config import *\n",
    "import timm\n",
    "from pathlib import Path\n",
    "\n",
    "# from data.fst_data import *\n",
    "\n",
    "# import wandb\n",
    "# wandb.init(project=\"classification\", entity=\"lbg030\")\n",
    "# wandb.config = {\n",
    "#   \"learning_rate\": LR,\n",
    "#   \"epochs\": EPOCH,\n",
    "#   \"batch_size\": BATCH\n",
    "# }\n",
    "\n",
    "random.seed(21)\n",
    "\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"-l\",\"--lambda_loss\",type=float, default=0.7, \n",
    "#                     help=\"Adjustment graph loss parameter between the labeled and unlabeled\")\n",
    "\n",
    "# parser.add_argument(\"-s\",\"--s_margin\", type=float, default=0.1,\n",
    "#                     help=\"Confidence margin of graph\")\n",
    "\n",
    "# parser.add_argument(\"-n\",\"--hidden_units\", type=int, default=128,\n",
    "#                     help=\"Number of hidden units of the graph\")\n",
    "\n",
    "# parser.add_argument(\"-r\",\"--dropout_rate\", type=float, default=0.3,\n",
    "#                     help=\"Dropout rate of the graph neural network\")\n",
    "parser.add_argument(\"-d\",\"--dataset\", type=str, default=\"fst\",\n",
    "                    help=\"\")\n",
    "\n",
    "parser.add_argument(\"-e\",\"--no_of_epochs\", type=int, default=EPOCH,\n",
    "                    \n",
    "                    help=\"Number of epochs for the active learner\")\n",
    "parser.add_argument(\"-m\",\"--method_type\", type=str, default=\"CoreSet\",\n",
    "                    help=\"\")\n",
    "\n",
    "parser.add_argument(\"-c\",\"--cycles\", type=int, default=CYCLES,\n",
    "                    help=\"Number of active learning cycles\")\n",
    "\n",
    "parser.add_argument(\"-t\",\"--total\", type=bool, default=False,\n",
    "                    help=\"Training on the entire dataset\")\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "\n",
    "##\n",
    "# Main\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    method = args.method_type\n",
    "    methods = ['CoreSet']\n",
    "    datasets = ['fst',]\n",
    "    assert method in methods, 'No method %s! Try options %s'%(method, methods)\n",
    "    assert args.dataset in datasets, 'No dataset %s! Try options %s'%(args.dataset, datasets)\n",
    "    # Model - create new instance for every cycle so that it resets\n",
    "    \n",
    "    \n",
    "            \n",
    "    # results = open('results_'+str(args.method_type)+\"_\"+args.dataset +'_main'+str(args.cycles)+str(args.total)+'.txt','w')\n",
    "    print(\"Dataset: %s\"%args.dataset)\n",
    "    print(\"Method type:%s\"%method)\n",
    "    if args.total:\n",
    "        TRIALS = 1\n",
    "        CYCLES = 1\n",
    "        \n",
    "    else:\n",
    "        CYCLES = args.cycles\n",
    "        \n",
    "    for trial in range(TRIALS):\n",
    "        res_list = []\n",
    "        # Load training and testing dataset\n",
    "        data_train, data_unlabeled, data_test, adden, NO_CLASSES, no_train = load_dataset(args.dataset)\n",
    "        \n",
    "        # Don't predefine budget size. Configure it in the config.py: ADDENDUM = adden\n",
    "        NUM_TRAIN = no_train\n",
    "        indices = list(range(NUM_TRAIN))\n",
    "        # print(trial, indices)\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        with torch.cuda.device(CUDA_VISIBLE_DEVICES):\n",
    "                \n",
    "                    #resnet18    = vgg11().to(device) \n",
    "                resnet18    = resnet.ResNet18().to(device)\n",
    "\n",
    "        models      = {'backbone': resnet18}\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        \n",
    "        # optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion      = nn.CrossEntropyLoss()\n",
    "        optim_backbone = optim.SGD(models['backbone'].parameters(), lr=LR, \n",
    "                momentum=MOMENTUM, weight_decay=WDECAY)\n",
    "\n",
    "        sched_backbone = torch.optim.lr_scheduler.CosineAnnealingLR(optim_backbone, T_max=200)\n",
    "        \n",
    "        optimizers = {'backbone': optim_backbone}\n",
    "        schedulers = {'backbone': sched_backbone}\n",
    "            \n",
    "        if args.total:\n",
    "            labeled_set = indices\n",
    "        else:\n",
    "            labeled_set = indices[:ADDENDUM]\n",
    "            unlabeled_set = [x for x in indices if x not in labeled_set]\n",
    "        \n",
    "        train_loader = DataLoader(data_train, batch_size=BATCH, num_workers=4, pin_memory=True, sampler=SubsetRandomSampler(labeled_set), drop_last = True)\n",
    "        test_loader = DataLoader(data_test,num_workers=4, batch_size=1)\n",
    "        \n",
    "        dataloaders  = {'train': train_loader, 'test': test_loader}\n",
    "        \n",
    "        print(f\"data_train = {len(data_train)},  data_test = {len(data_test)}\")\n",
    "        print(f\"no_train = {NUM_TRAIN}\")   \n",
    "        \n",
    "        for cycle in range(CYCLES):\n",
    "            \n",
    "            optim_backbone = optim.SGD(models['backbone'].parameters(), lr=LR, \n",
    "                momentum=MOMENTUM, weight_decay=WDECAY)\n",
    "            \n",
    "            # Randomly sample 10000 unlabeled data points\n",
    "            if not args.total:\n",
    "                random.shuffle(unlabeled_set)\n",
    "                subset = unlabeled_set[:SUBSET]\n",
    "            \n",
    "            testing(dataloaders)\n",
    "    \n",
    "            # Training and testing\n",
    "            train_loss = train(models, method, criterion, optimizers, schedulers, dataloaders, args.no_of_epochs, EPOCHL)\n",
    "            # print(f'train loss : {train_loss:.4f}')\n",
    "            # metrics['train_loss'] = round(train_loss, 4)\n",
    "            # train(models, method, criterion, optimizers, schedulers, dataloaders, args.no_of_epochs, EPOCHL)\n",
    "            metrics, results = test(models, EPOCH, method, dataloaders, mode='test')\n",
    "            print(f\"accuracy : {metrics['accuracy']:.4f}\")\n",
    "            print(f\"f1 score : {metrics['f1_score']:.4f}\")\n",
    "            print(f\"precision : {metrics['precision']:.4f}\")\n",
    "            print(f\"recall : {metrics['recall']:.4f}\")\n",
    "            \n",
    "            # acc_l = metrics['accuracy']\n",
    "            # f1_l = metrics['f1_score']\n",
    "            # pre_l = metrics['precision']\n",
    "            # rec_l = metrics['recall']\n",
    "            \n",
    "            # res_list.append([acc_l,f1_l,pre_l,rec_l])\n",
    "    #         wandb.log({'metric/accuracy' : metrics['accuracy'],\n",
    "    #         'metric/f1_score' : metrics['f1_score'],\n",
    "    #         'metric/precision' : metrics['precision'],\n",
    "    #         'metric/recall' : metrics['recall'],\n",
    "    # })\n",
    "            \n",
    "            print('Trial {}/{} || Cycle {}/{} || Label set size {}'.format(trial+1, TRIALS, cycle+1, CYCLES, len(labeled_set)))\n",
    "            \n",
    "            # # print(labeled_set)\n",
    "            # np.array([method, trial+1, TRIALS, cycle+1, CYCLES, len(labeled_set), acc]).tofile(results, sep=\" \")\n",
    "            # results.write(\"\\n\")\n",
    "\n",
    "            if cycle == (CYCLES-1):\n",
    "                # Reached final training cycle\n",
    "                print(\"Finished.\")\n",
    "                break\n",
    "            \n",
    "            if trial == 0 and cycle == 0:\n",
    "                torch.save(models, str(Path(PATH, 'best.pt')))\n",
    "                best_f1 = 0\n",
    "                \n",
    "            if best_f1 < metrics['f1_score']:\n",
    "                best_f1 = metrics['f1_score']\n",
    "                torch.save(models, str(Path(PATH, 'best.pt')))\n",
    "                \n",
    "            # Get the indices of the unlabeled samples to train on next cycle\n",
    "            arg = query_samples(models, method, data_unlabeled, subset, labeled_set, cycle, args)\n",
    "            \n",
    "            # print(f\"arg = {arg}\")\n",
    "            # Update the labeled dataset and the unlabeled dataset, respectively\n",
    "            labeled_set += list(torch.tensor(subset)[arg][-ADDENDUM:].numpy())\n",
    "            listd = list(torch.tensor(subset)[arg][:-ADDENDUM].numpy()) \n",
    "            unlabeled_set = listd + unlabeled_set[SUBSET:]\n",
    "\n",
    "            dataloaders['train'] = DataLoader(data_train, batch_size=BATCH,sampler=SubsetRandomSampler(labeled_set),\n",
    "                                            pin_memory=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "611d41f9c0d119f726c146a3d3bc40ce419f45abac4b6c5efabc98622bc9d855"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
