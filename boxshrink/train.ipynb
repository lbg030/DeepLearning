{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "from config import (\n",
    "    ACTIVATION,\n",
    "    BATCH_SIZE,\n",
    "    BEST_MODEL_DIR,\n",
    "    CLASSES,\n",
    "    DATA_DIR,\n",
    "    BOX_DIR,\n",
    "    RAPID_DIR,\n",
    "    ROBUST_DIR,\n",
    "    DECODER,\n",
    "    DEVICE,\n",
    "    ENCODER,\n",
    "    ENCODER_WEIGHTS,\n",
    "    EVAL_ON_MASKS,\n",
    "    EXPORT_BEST_MODEL,\n",
    "    EXPORT_CSV_DIR,\n",
    "    GAMMA,\n",
    "    LEARNING_RATE,\n",
    "    LEARNING_RATE_SCHEDULING,\n",
    "    LOSS,\n",
    "    MODE,\n",
    "    N_EPOCHS,\n",
    "    OPTIMIZER,\n",
    "    PER_X_BATCH,\n",
    "    PER_X_EPOCH,\n",
    "    PER_X_EPOCH_PLOT,\n",
    "    SCHEDULE_TYPE,\n",
    "    START_EPOCH,\n",
    "    STATE,\n",
    "    STEP_SIZE,\n",
    "    TRAINING_INPUT,\n",
    "    WEIGHT_DECAY,\n",
    ")\n",
    "from dataset import Colonoscopy_Dataset\n",
    "from tools import (\n",
    "    epoch_time,\n",
    "    human_sort,\n",
    "    label_colors,\n",
    "    return_batch_information,\n",
    "    return_files_in_directory,\n",
    ")\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import JaccardIndex\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_files = return_files_in_directory(DATA_DIR + \"/original\", \".tif\")\n",
    "mask_files = return_files_in_directory(DATA_DIR + \"/ground_truth\", \".tif\")\n",
    "box_files = return_files_in_directory(BOX_DIR, \".png\")\n",
    "rapid_masks = return_files_in_directory(RAPID_DIR, \".png\")\n",
    "robust_masks = return_files_in_directory(ROBUST_DIR, \".png\")\n",
    "\n",
    "human_sort(image_files)\n",
    "human_sort(mask_files)\n",
    "human_sort(box_files)\n",
    "human_sort(rapid_masks)\n",
    "human_sort(robust_masks)\n",
    "\n",
    "\n",
    "if TRAINING_INPUT == \"boxes\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        image_files, box_files, test_size=0.1, random_state=1\n",
    "    )\n",
    "elif TRAINING_INPUT == \"rapid_boxshrink\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        image_files, rapid_masks, test_size=0.1, random_state=1\n",
    "    )\n",
    "elif TRAINING_INPUT == \"robust_boxshrink\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        image_files, robust_masks, test_size=0.1, random_state=1\n",
    "    )\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        image_files, mask_files, test_size=0.1, random_state=1\n",
    "    )\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.11111, random_state=1\n",
    ")  # 0.1111 x 0.9 = 0.1\n",
    "\n",
    "if EVAL_ON_MASKS == True:\n",
    "    if TRAINING_INPUT == \"boxes\":\n",
    "        y_val = [\n",
    "            i.replace(\"boxmasks\", \"ground_truth\").replace(\"png\", \"tif\") for i in y_val\n",
    "        ]\n",
    "        y_test = [\n",
    "            i.replace(\"boxmasks\", \"ground_truth\").replace(\"png\", \"tif\") for i in y_test\n",
    "        ]\n",
    "    elif TRAINING_INPUT == \"rapid_boxshrink\":\n",
    "        y_val = [\n",
    "            i.replace(\"testing/rapid_boxshrink\", \"ground_truth\").replace(\"png\", \"tif\")\n",
    "            for i in y_val\n",
    "        ]\n",
    "        y_test = [\n",
    "            i.replace(\"testing/rapid_boxshrink\", \"ground_truth\").replace(\"png\", \"tif\")\n",
    "            for i in y_test\n",
    "        ]\n",
    "    elif TRAINING_INPUT == \"robust_boxshrink\":\n",
    "        y_val = [\n",
    "            i.replace(\"testing/robust_boxshrink\", \"ground_truth\").replace(\"png\", \"tif\")\n",
    "            for i in y_val\n",
    "        ]\n",
    "        y_test = [\n",
    "            i.replace(\"testing/robust_boxshrink\", \"ground_truth\").replace(\"png\", \"tif\")\n",
    "            for i in y_test\n",
    "        ]\n",
    "\n",
    "train_dataset = Colonoscopy_Dataset(X_train, y_train, limit_dataset_size=50)\n",
    "\n",
    "test_dataset = Colonoscopy_Dataset(X_test, y_test, limit_dataset_size=50)\n",
    "\n",
    "val_dataset = Colonoscopy_Dataset(X_val, y_val, limit_dataset_size=50)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "if DECODER == \"Unet\":\n",
    "    model = smp.Unet(\n",
    "        encoder_name=ENCODER,\n",
    "        encoder_weights=ENCODER_WEIGHTS,\n",
    "        classes=len(CLASSES),\n",
    "        activation=ACTIVATION,\n",
    "    )\n",
    "\n",
    "elif DECODER == \"DeepLabV3+\":\n",
    "    model = smp.Unet(\n",
    "        encoder_name=ENCODER,\n",
    "        encoder_weights=ENCODER_WEIGHTS,\n",
    "        classes=len(CLASSES),\n",
    "        activation=ACTIVATION,\n",
    "    )\n",
    "\n",
    "if OPTIMIZER == \"SGD\":\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "if OPTIMIZER == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "    # Learning rate scheduling\n",
    "if LEARNING_RATE_SCHEDULING == True and SCHEDULE_TYPE == \"STEP\":\n",
    "    scheduler = StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA, verbose=True)\n",
    "elif LEARNING_RATE_SCHEDULING == True and SCHEDULE_TYPE == \"EXPONENTIAL\":\n",
    "    STEP_SIZE = \"Not needed\"\n",
    "    scheduler = ExponentialLR(optimizer, gamma=GAMMA, verbose=True)\n",
    "elif LEARNING_RATE_SCHEDULING == False:\n",
    "    STEP_SIZE = \"No scheduling\"\n",
    "    GAMMA = \"No scheduling\"\n",
    "    SCHEDULE_TYPE = \"No scheduling\"\n",
    "\n",
    "# Setup date for model name\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "datestring = today.strftime(\"%Y-%m-%d\")\n",
    "# Instantiate accuracy and loss tracker\n",
    "best_train_loss = float(\"inf\")\n",
    "best_valid_loss = float(\"inf\")\n",
    "best_valid_iou = 0\n",
    "best_train_iou = 0\n",
    "\n",
    "# Build dataframe to collect loss and metric data\n",
    "df_train = pd.DataFrame(columns=[\"epoch\", \"loss\", \"avg_loss\", \"mean_iou\"])\n",
    "df_val = pd.DataFrame(columns=[\"epoch\", \"loss\", \"avg_loss\", \"mean_iou\"])\n",
    "# # Determine column types train\n",
    "# Dummy entry to prevent visualization bug that large values are plotted as zero\n",
    "if LOSS == \"CrossEntropyLoss\":\n",
    "    criterion = CrossEntropyLoss()\n",
    "    criterion_double = CrossEntropyLoss()\n",
    "jaccard = JaccardIndex(num_classes=len(CLASSES), reduction=\"elementwise_mean\").to(\n",
    "    DEVICE\n",
    ")\n",
    "\n",
    "validate_training_targets = '/'.join(y_train[0].split('/')[-4:])\n",
    "validate_training_targets\n",
    "validate_val_targets = '/'.join(y_val[0].split('/')[-4:])\n",
    "validate_val_targets\n",
    "validate_test_targets = '/'.join(y_test[0].split('/')[-4:])\n",
    "validate_test_targets\n",
    "\n",
    "# Make sure we have the correct labels\n",
    "print(f\"Train targets from: {validate_training_targets}\")\n",
    "print(f\"Val targets from: {validate_val_targets}\")\n",
    "print(f\"Test targets from: {validate_test_targets}\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "train_start_time = time.time()\n",
    "train_iou_score = torch.tensor([0])\n",
    "early_stopped = 0\n",
    "for epoch in range(START_EPOCH, N_EPOCHS):\n",
    "    model.train()\n",
    "    batch, running_epoch_iou, running_epoch_loss = 0, 0.0, 0.0\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for train_inputs, train_labels, train_org_images in tepoch:\n",
    "            batch += 1\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            train_inputs, train_labels, train_org_images = (\n",
    "                train_inputs.to(DEVICE),\n",
    "                train_labels.to(DEVICE),\n",
    "                train_org_images.to(DEVICE),\n",
    "            )\n",
    "            # forward\n",
    "            train_outputs = model(train_inputs).to(DEVICE)\n",
    "            out_max = (\n",
    "                torch.argmax(train_outputs, dim=1, keepdim=True)[:, -1, :, :]\n",
    "                .cpu()\n",
    "                .detach()\n",
    "                .numpy()\n",
    "            )\n",
    "            train_loss = criterion(train_outputs, train_labels)\n",
    "            train_loss.backward()\n",
    "            if epoch % PER_X_EPOCH == 0 and batch % PER_X_BATCH == 0:\n",
    "                return_batch_information(\n",
    "                    train_org_images,\n",
    "                    out_max,\n",
    "                    train_labels,\n",
    "                    1,\n",
    "                    CLASSES,\n",
    "                    label_colors=label_colors,\n",
    "                )\n",
    "            optimizer.step()\n",
    "            model.eval()\n",
    "            train_iou_score = jaccard(train_outputs, train_labels).to(DEVICE).item()\n",
    "            model.train()\n",
    "            running_epoch_iou += train_iou_score\n",
    "            train_loss = float(train_loss.item())\n",
    "            running_epoch_loss += train_loss\n",
    "            # print statistics\n",
    "            tepoch.set_postfix(\n",
    "                phase=\"Training\",\n",
    "                loss=train_loss,\n",
    "                iou=train_iou_score,\n",
    "                epoch_iou=running_epoch_iou / batch,\n",
    "                epoch_loss=running_epoch_loss / batch,\n",
    "            )\n",
    "        train_mean_epoch_iou, train_mean_epoch_loss = (\n",
    "            running_epoch_iou / batch,\n",
    "            running_epoch_loss / batch,\n",
    "        )\n",
    "    if best_train_loss > train_mean_epoch_loss:\n",
    "        best_train_loss = train_mean_epoch_loss\n",
    "    if best_train_iou < train_mean_epoch_iou:\n",
    "        best_train_iou = train_mean_epoch_iou\n",
    "    # Save results to dataframe\n",
    "    if epoch == 0:\n",
    "        train_row = {\n",
    "            \"epoch\": int(epoch),\n",
    "            \"loss\": float(train_mean_epoch_loss),\n",
    "            \"avg_loss\": float(train_mean_epoch_loss),\n",
    "            \"mean_iou\": float(train_mean_epoch_iou),\n",
    "        }\n",
    "    else:\n",
    "        # Get moving average\n",
    "        train_avg = df_train[\"loss\"].ewm(com=0.99).mean()\n",
    "        train_row = {\n",
    "            \"epoch\": int(epoch),\n",
    "            \"loss\": float(train_loss),\n",
    "            \"avg_loss\": train_avg[(epoch - 1)],\n",
    "            \"mean_iou\": train_mean_epoch_iou,\n",
    "        }\n",
    "\n",
    "    df_train = df_train.append(train_row, ignore_index=True)\n",
    "    # Decay Learning Rate at x steps\n",
    "    if LEARNING_RATE_SCHEDULING == True:\n",
    "        scheduler.step()\n",
    "    # Delete variables to free memory\n",
    "    del running_epoch_iou, running_epoch_loss, train_loss, train_iou_score\n",
    "\n",
    "    ### Running validation loop\n",
    "    batch, running_epoch_iou, running_epoch_loss = 0, 0.0, 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader, unit=\"batch\") as tepoch:\n",
    "            for val_inputs, val_labels, val_org_images in tepoch:\n",
    "                batch += 1\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                val_inputs, val_labels, val_org_images = (\n",
    "                    val_inputs.to(DEVICE),\n",
    "                    val_labels.to(DEVICE),\n",
    "                    val_org_images.to(DEVICE),\n",
    "                )\n",
    "                # forward\n",
    "                val_outputs = model(val_inputs)\n",
    "                # Collect metrics\n",
    "                val_iou_score = jaccard(val_outputs, val_labels).item()\n",
    "                val_loss = criterion(val_outputs, val_labels).item()\n",
    "                # Collect data for dataframe\n",
    "                running_epoch_iou += val_iou_score\n",
    "                running_epoch_loss += val_loss\n",
    "                # print statistics\n",
    "                tepoch.set_postfix(\n",
    "                    phase=\"Validation\",\n",
    "                    loss=val_loss,\n",
    "                    iou=val_iou_score,\n",
    "                    epoch_iou=running_epoch_iou / batch,\n",
    "                    epoch_loss=running_epoch_loss / batch,\n",
    "                )\n",
    "        val_mean_epoch_iou, val_mean_epoch_loss = (\n",
    "            running_epoch_iou / batch,\n",
    "            running_epoch_loss / batch,\n",
    "        )\n",
    "        # Save results to dataframe\n",
    "        if epoch == 0:\n",
    "            val_row = {\n",
    "                \"epoch\": int(epoch),\n",
    "                \"loss\": float(val_mean_epoch_loss),\n",
    "                \"avg_loss\": float(val_mean_epoch_loss),\n",
    "                \"mean_iou\": val_mean_epoch_iou,\n",
    "            }\n",
    "        else:\n",
    "            val_avg = df_val[\"loss\"].ewm(com=0.99).mean()\n",
    "            val_row = {\n",
    "                \"epoch\": int(epoch),\n",
    "                \"loss\": float(val_loss),\n",
    "                \"avg_loss\": val_avg[(epoch - 1)],\n",
    "                \"mean_iou\": val_mean_epoch_iou,\n",
    "            }\n",
    "        df_val = df_val.append(val_row, ignore_index=True)\n",
    "        if best_valid_loss > val_mean_epoch_loss:\n",
    "            # Update best metrics\n",
    "            best_valid_loss = val_mean_epoch_loss\n",
    "        if best_valid_iou < val_mean_epoch_iou:\n",
    "            best_valid_iou = val_mean_epoch_iou\n",
    "            best_model = copy.deepcopy(model)\n",
    "            if epoch > 2 and EXPORT_BEST_MODEL == True:\n",
    "                model_name = \"_\".join(\n",
    "                    [\n",
    "                        datestring,\n",
    "                        STATE,\n",
    "                        MODE,\n",
    "                        DECODER,\n",
    "                        OPTIMIZER,\n",
    "                        LOSS,\n",
    "                        ENCODER,\n",
    "                        str(len(train_dataset)),\n",
    "                        \"images\",\n",
    "                        LOSS,\n",
    "                        \"loss\",\n",
    "                        str(best_valid_loss).replace(\".\", \"_\"),\n",
    "                        \"iou\",\n",
    "                        str(val_mean_epoch_iou),\n",
    "                        \"epoch\",\n",
    "                        str(epoch),\n",
    "                        \".pth\",\n",
    "                    ]\n",
    "                )\n",
    "                # save model\n",
    "                path = os.path.join(BEST_MODEL_DIR, model_name)\n",
    "                torch.save(best_model.state_dict(), path)\n",
    "                print(f\"Model saved! Name is {model_name}\")\n",
    "        if epoch % PER_X_EPOCH_PLOT == 0:\n",
    "            plt.plot(df_train[\"epoch\"], df_train[\"avg_loss\"], label=\"Train Loss\")\n",
    "            plt.plot(df_val[\"epoch\"], df_val[\"avg_loss\"], label=\"Valid Loss\")\n",
    "            plt.plot(df_val[\"epoch\"], df_val[\"mean_iou\"], label=\"Mean IoU\")\n",
    "            plt.legend()\n",
    "            plt.title(\"Performance\")\n",
    "            plot = plt.gcf()\n",
    "            plt.show()\n",
    "        train_df_name = \"_\".join(\n",
    "            [\n",
    "                datestring,\n",
    "                \"train\",\n",
    "                MODE,\n",
    "                DECODER,\n",
    "                OPTIMIZER,\n",
    "                LOSS,\n",
    "                ENCODER,\n",
    "                str(len(train_dataset)),\n",
    "                \"images\",\n",
    "                \".csv\",\n",
    "            ]\n",
    "        )\n",
    "        valid_df_name = \"_\".join(\n",
    "            [\n",
    "                datestring,\n",
    "                \"valid\",\n",
    "                MODE,\n",
    "                DECODER,\n",
    "                OPTIMIZER,\n",
    "                LOSS,\n",
    "                ENCODER,\n",
    "                str(len(train_dataset)),\n",
    "                \"images\",\n",
    "                \".csv\",\n",
    "            ]\n",
    "        )\n",
    "        df_train.to_csv(os.path.join(EXPORT_CSV_DIR, train_df_name))\n",
    "        df_val.to_csv(os.path.join(EXPORT_CSV_DIR, valid_df_name))\n",
    "        if epoch > 5:\n",
    "            last_runs = df_train[\"loss\"][-5:]\n",
    "            # Get min and max of that window\n",
    "            min_loss_last_runs = last_runs.min()\n",
    "            max_loss_last_runs = last_runs.max()\n",
    "            difference = max_loss_last_runs - min_loss_last_runs\n",
    "            if difference < 0.001:\n",
    "                print(\"Stopped Training because it doesn't improve anymore.\")\n",
    "                train_end_time = time.time()\n",
    "                # Get minutes and seconds to write to ML flow\n",
    "                train_mins, train_secs = epoch_time(train_start_time, train_end_time)\n",
    "                batch, running_epoch_iou, running_epoch_loss = 0, 0.0, 0.0\n",
    "                best_model.eval()\n",
    "                with torch.no_grad():\n",
    "                    with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "                        for test_inputs, test_labels, test_org_images in tepoch:\n",
    "                            batch += 1\n",
    "                            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                            test_inputs, test_labels, test_org_images = (\n",
    "                                test_inputs.to(DEVICE),\n",
    "                                test_labels.to(DEVICE),\n",
    "                                test_org_images.to(DEVICE),\n",
    "                            )\n",
    "                            # forward\n",
    "                            test_outputs = best_model(test_inputs)\n",
    "                            # Collect metrics\n",
    "                            test_iou_score = jaccard(test_outputs, test_labels).item()\n",
    "                            test_loss = criterion(test_outputs, test_labels).item()\n",
    "                            # Collect data for dataframe\n",
    "                            running_epoch_iou += test_iou_score\n",
    "                            running_epoch_loss += test_loss\n",
    "                            # print statistics\n",
    "                            tepoch.set_postfix(\n",
    "                                phase=\"Validation\",\n",
    "                                loss=test_loss,\n",
    "                                iou=test_iou_score,\n",
    "                                epoch_iou=running_epoch_iou / batch,\n",
    "                                epoch_loss=running_epoch_loss / batch,\n",
    "                            )\n",
    "                    test_mean_epoch_iou, test_mean_epoch_loss = (\n",
    "                        running_epoch_iou / batch,\n",
    "                        running_epoch_loss / batch,\n",
    "                    )\n",
    "                print(\"\")\n",
    "                print(\n",
    "                    f\"Performance on test set: {val_mean_epoch_iou} IoU and {val_mean_epoch_loss} Loss\"\n",
    "                )\n",
    "                print(f\"Training time was {train_mins, train_secs}\")\n",
    "                early_stopped += 1\n",
    "                break\n",
    "if early_stopped == 0:\n",
    "    train_end_time = time.time()\n",
    "    # Get minutes and seconds to write to ML flow\n",
    "    train_mins, train_secs = epoch_time(train_start_time, train_end_time)\n",
    "    # End run and get status\n",
    "    batch, running_epoch_iou, running_epoch_loss = 0, 0.0, 0.0\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "            for test_inputs, test_labels, test_org_images in tepoch:\n",
    "                batch += 1\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                test_inputs, test_labels, test_org_images = (\n",
    "                    test_inputs.to(DEVICE),\n",
    "                    test_labels.to(DEVICE),\n",
    "                    test_org_images.to(DEVICE),\n",
    "                )\n",
    "                # forward\n",
    "                test_outputs = best_model(test_inputs)\n",
    "                # Collect metrics\n",
    "                test_iou_score = jaccard(test_outputs, test_labels).item()\n",
    "                test_loss = criterion(test_outputs, test_labels).item()\n",
    "                # Collect data for dataframe\n",
    "                running_epoch_iou += test_iou_score\n",
    "                running_epoch_loss += test_loss\n",
    "                # print statistics\n",
    "                tepoch.set_postfix(\n",
    "                    phase=\"Validation\",\n",
    "                    loss=test_loss,\n",
    "                    iou=test_iou_score,\n",
    "                    epoch_iou=running_epoch_iou / batch,\n",
    "                    epoch_loss=running_epoch_loss / batch,\n",
    "                )\n",
    "        test_mean_epoch_iou, test_mean_epoch_loss = (\n",
    "            running_epoch_iou / batch,\n",
    "            running_epoch_loss / batch,\n",
    "        )\n",
    "    print(f\"Training time was {train_mins, train_secs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('boxshrink')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e03cce523887ef4ae3cc71c66ab4ee9a46035781549cd05776eda36e5299632"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
